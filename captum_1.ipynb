{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "import cbig.osama2024.dataloader as dataloader\n",
    "import cbig.osama2024.model as model\n",
    "importlib.reload(model)\n",
    "\n",
    "#from cbig.osama2024.model import osama\n",
    "\n",
    "import cbig.osama2024.misc as misc\n",
    "from cbig.osama2024.model import MODEL_DICT\n",
    "\n",
    "\n",
    "# load data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import integrated gradients from captum\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MinRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"examples/output/model.pt\"\n",
    "data_path = \"output/val.pkl\"\n",
    "dict_path = \"output/model_state_dict.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path, 'rb') as f:\n",
    "#     data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "with open(data_path, 'rb') as fhandler:\n",
    "        data = pickle.load(fhandler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_measures = len(data['train'].value_fields())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CDRSB' 'ADAS11' 'ADAS13' 'MMSE' 'RAVLT_immediate' 'RAVLT_learning'\n",
      " 'RAVLT_forgetting' 'RAVLT_perc_forgetting' 'MOCA' 'FAQ' 'Entorhinal'\n",
      " 'Fusiform' 'Hippocampus' 'ICV' 'MidTemp' 'Ventricles' 'WholeBrain' 'AV45'\n",
      " 'FDG' 'ABETA_UPENNBIOMK9_04_19_17' 'TAU_UPENNBIOMK9_04_19_17'\n",
      " 'PTAU_UPENNBIOMK9_04_19_17']\n"
     ]
    }
   ],
   "source": [
    "print(data['train'].value_fields())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['baseline', 'pred_start', 'duration', 'mean', 'stds', 'VentICVstd', 'train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model param initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'MinRNN'\n",
    "nb_classes = 3\n",
    "nb_layers = 1\n",
    "h_size = 512\n",
    "h_drop = 0.1\n",
    "i_drop = 0.1\n",
    "lr = 5e-4\n",
    "weight_decay = 5e-7\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = MODEL_DICT[model_type]\n",
    "model = model_class(\n",
    "    nb_classes = nb_classes,\n",
    "    nb_measures = nb_measures,\n",
    "    nb_layers = nb_layers,\n",
    "    h_size = h_size,\n",
    "    h_drop = h_drop,\n",
    "    i_drop = i_drop)\n",
    "\n",
    "setattr(model, 'mean', data['mean'])\n",
    "setattr(model, 'std', data['stds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinimalRNN(\n",
      "  (hid2category): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (hid2measures): Linear(in_features=512, out_features=22, bias=True)\n",
      "  (cells): ModuleList(\n",
      "    (0): MinimalRNNCell(\n",
      "      (W): Linear(in_features=25, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "log = print if verbose else lambda *x, **i: None\n",
    "device = torch.device(\n",
    "        'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "log(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=lr, weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinimalRNN(\n",
       "  (hid2category): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (hid2measures): Linear(in_features=512, out_features=22, bias=True)\n",
       "  (cells): ModuleList(\n",
       "    (0): MinimalRNNCell(\n",
       "      (W): Linear(in_features=25, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dictionary into model\n",
    "model.load_state_dict(torch.load(dict_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(model)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Apply Integrated Gradients to the chosen data point\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m attributions, approximation_error \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mattribute(\u001b[43mdata_point\u001b[49m, target\u001b[38;5;241m=\u001b[39mtarget_class_index, return_convergence_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# The attributions tensor contains the sensitivity of the model's output to each input feature\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttributions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, attributions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_point' is not defined"
     ]
    }
   ],
   "source": [
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# Apply Integrated Gradients to the chosen data point\n",
    "attributions, approximation_error = ig.attribute(data_point, target=target_class_index, return_convergence_delta=True)\n",
    "\n",
    "# The attributions tensor contains the sensitivity of the model's output to each input feature\n",
    "print(\"Attributions:\", attributions)\n",
    "print(\"Approximation Error (Delta):\", approximation_error.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Integrated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_integrated_gradients(model, data_point, target_class_index=0):\n",
    "    # Create an instance of IntegratedGradients for the RNN model\n",
    "    ig = IntegratedGradients(model)\n",
    "\n",
    "    # Apply Integrated Gradients to the chosen data point\n",
    "    attributions, approximation_error = ig.attribute(data_point, target=target_class_index, return_convergence_delta=True)\n",
    "\n",
    "    # The attributions tensor contains the sensitivity of the model's output to each input feature\n",
    "    print(\"Attributions:\", attributions)\n",
    "    print(\"Approximation Error (Delta):\", approximation_error.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RnnModelInterp.forward() missing 1 required positional argument: '_val_seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m time_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(time_seq, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Apply Integrated Gradients to the current data point\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[43mapply_integrated_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Append attributions to the list\u001b[39;00m\n\u001b[1;32m     52\u001b[0m attributions_list\u001b[38;5;241m.\u001b[39mappend(attributions)\n",
      "Cell \u001b[0;32mIn[95], line 23\u001b[0m, in \u001b[0;36mapply_integrated_gradients\u001b[0;34m(model, cat_seq, value_seq, time_seq, target_class_index)\u001b[0m\n\u001b[1;32m     20\u001b[0m input_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([cat_seq, value_seq], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Apply Integrated Gradients to the input sequence\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m attributions, approximation_error \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Return the computed attributions and approximation error\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attributions, approximation_error\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/captum/_utils/common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: RnnModelInterp.forward() missing 1 required positional argument: '_val_seq'"
     ]
    }
   ],
   "source": [
    "def apply_integrated_gradients(model, cat_seq, value_seq, time_seq, target_class_index=0):\n",
    "    \"\"\"\n",
    "    Apply Integrated Gradients to the given model and data point.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        cat_seq: Sequence of categorical features.\n",
    "        value_seq: Sequence of numerical features.\n",
    "        time_seq: Sequence of time points.\n",
    "        target_class_index: Index of the target class for which to compute attributions.\n",
    "        \n",
    "    Returns:\n",
    "        attributions: Integrated Gradients attributions for the input features.\n",
    "        approximation_error: Approximation error computed during the attribution process.\n",
    "    \"\"\"\n",
    "    # Create an instance of IntegratedGradients for the RNN model\n",
    "    ig = IntegratedGradients(model)\n",
    "\n",
    "    # Concatenate categorical and numerical features along the time dimension\n",
    "    input_seq = torch.cat([cat_seq, value_seq], dim=-1)\n",
    "\n",
    "    # Apply Integrated Gradients to the input sequence\n",
    "    attributions, approximation_error = ig.attribute(input_seq, target=target_class_index, return_convergence_delta=True)\n",
    "\n",
    "    # Return the computed attributions and approximation error\n",
    "    return attributions, approximation_error\n",
    "\n",
    "\n",
    "test_data = data['test']\n",
    "    \n",
    "attributions_list = []\n",
    "\n",
    "\n",
    "# Iterate over individual data points in the test data\n",
    "for i in range(len(test_data)):\n",
    "    data_point = test_data.next()  # Get the next data point using the 'next' method of the Sorted object\n",
    "    \n",
    "    # Convert data point to appropriate format for applying Integrated Gradients\n",
    "    cat_seq = data_point['cat']\n",
    "    value_seq = data_point['val']\n",
    "    time_seq = data_point['tp']\n",
    "\n",
    "    # Convert data to tensors and move to device\n",
    "    cat_seq = torch.tensor(cat_seq, dtype=torch.float32).to(device)\n",
    "    value_seq = torch.tensor(value_seq, dtype=torch.float32).to(device)\n",
    "    time_seq = torch.tensor(time_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Apply Integrated Gradients to the current data point\n",
    "    attributions = apply_integrated_gradients(model, cat_seq, value_seq, time_seq)\n",
    "\n",
    "    # Append attributions to the list\n",
    "    attributions_list.append(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[1;32m---> 16\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Choose a data point from the test set for applying Integrated Gradients\u001b[39;00m\n\u001b[0;32m     19\u001b[0m data_point, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:202\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:202\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\n",
    "#         'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# model = torch.load(args.checkpoint)\n",
    "# model.to(device)\n",
    "\n",
    "# with open(args.data, 'rb') as fhandler:\n",
    "#     data = pickle.load(fhandler)\n",
    "\n",
    "# Assuming 'test' contains your test data\n",
    "\n",
    "#import dataloader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(*data['test']), batch_size=64, shuffle=False)\n",
    "\n",
    "# Choose a data point from the test set for applying Integrated Gradients\n",
    "data_point, _ = next(iter(test_loader))\n",
    "data_point = data_point.to(device)\n",
    "\n",
    "# Apply Integrated Gradients\n",
    "apply_integrated_gradients(model, data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Predict function of RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_subject(model, cat_seq, value_seq, time_seq):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression for a subject\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        cat_seq: sequence of diagnosis [nb_input_timpoints, nb_classes]\n",
    "        value_seq: sequence of other features [nb_input_timpoints, nb_features]\n",
    "        time_seq: months from baseline [nb_output_timpoints, nb_features]\n",
    "    nb_input_timpoints <= nb_output_timpoints\n",
    "    Returns:\n",
    "        out_cat: predicted diagnosis\n",
    "        out_val: predicted features\n",
    "    \"\"\"\n",
    "    in_val = np.full((len(time_seq), ) + value_seq.shape[1:], np.nan)\n",
    "    in_val[:len(value_seq)] = value_seq\n",
    "\n",
    "    in_cat = np.full((len(time_seq), ) + cat_seq.shape[1:], np.nan)\n",
    "    in_cat[:len(cat_seq)] = cat_seq\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_cat, out_val = model(in_cat, in_val)\n",
    "    out_cat = out_cat.cpu().numpy()\n",
    "    out_val = out_val.cpu().numpy()\n",
    "\n",
    "    assert out_cat.shape[1] == out_val.shape[1] == 1\n",
    "\n",
    "    return out_cat, out_val\n",
    "\n",
    "\n",
    "def predict(model, dataset, pred_start, duration, baseline):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression using a trained model\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        dataset: test data\n",
    "        pred_start (dictionary): the date at which prediction begins\n",
    "        duration (dictionary): how many months into the future to predict\n",
    "        baseline (dictionary): the baseline date\n",
    "    Returns:\n",
    "        dictionary which contains the following key/value pairs:\n",
    "            subjects: list of subject IDs\n",
    "            DX: list of diagnosis prediction for each subject\n",
    "            ADAS13: list of ADAS13 prediction for each subject\n",
    "            Ventricles: list of ventricular volume prediction for each subject\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ret = {'subjects': dataset.subjects}\n",
    "    ret['DX'] = []  # 1. likelihood of NL, MCI, and Dementia\n",
    "    ret['ADAS13'] = []  # 2. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['Ventricles'] = []  # 3. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['dates'] = misc.make_date_col(\n",
    "        [pred_start[s] for s in dataset.subjects], duration)\n",
    "\n",
    "    col = ['ADAS13', 'Ventricles', 'ICV']\n",
    "    indices = misc.get_index(list(dataset.value_fields()), col)\n",
    "    mean = model.mean[col].values.reshape(1, -1)\n",
    "    stds = model.stds[col].values.reshape(1, -1)\n",
    "\n",
    "    for data in dataset:\n",
    "        rid = data['rid']\n",
    "        all_tp = data['tp'].squeeze(axis=1)\n",
    "        start = misc.month_between(pred_start[rid], baseline[rid])\n",
    "        assert np.all(all_tp == np.arange(len(all_tp)))\n",
    "        mask = all_tp < start\n",
    "        itime = np.arange(start + duration)\n",
    "        icat = np.asarray(\n",
    "            [misc.to_categorical(c, 3) for c in data['cat'][mask]])\n",
    "        ival = data['val'][:, None, :][mask]\n",
    "\n",
    "        ocat, oval = predict_subject(model, icat, ival, itime)\n",
    "        oval = oval[-duration:, 0, indices] * stds + mean\n",
    "\n",
    "        ret['DX'].append(ocat[-duration:, 0, :])\n",
    "        ret['ADAS13'].append(misc.add_ci_col(oval[:, 0], 1, 0, 85))\n",
    "        ret['Ventricles'].append(\n",
    "            misc.add_ci_col(oval[:, 1] / oval[:, 2], 5e-4, 0, 1))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_subject_with_gradients(model, cat_seq, value_seq, time_seq, target_class_index=0):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression for a subject and calculate Integrated Gradients\n",
    "    Args:\n",
    "        model: trained PyTorch model\n",
    "        cat_seq: sequence of diagnosis [nb_input_timpoints, nb_classes]\n",
    "        value_seq: sequence of other features [nb_input_timpoints, nb_features]\n",
    "        time_seq: months from baseline [nb_output_timpoints, nb_features]\n",
    "        target_class_index: index of the target class for Integrated Gradients\n",
    "    nb_input_timpoints <= nb_output_timpoints\n",
    "    Returns:\n",
    "        out_cat: predicted diagnosis\n",
    "        out_val: predicted features\n",
    "        attributions: Integrated Gradients attributions\n",
    "        approximation_error: Delta value for approximation error\n",
    "    \"\"\"\n",
    "    in_val = np.full((len(time_seq), ) + value_seq.shape[1:], np.nan)\n",
    "    in_val[:len(value_seq)] = value_seq\n",
    "\n",
    "    in_cat = np.full((len(time_seq), ) + cat_seq.shape[1:], np.nan)\n",
    "    in_cat[:len(cat_seq)] = cat_seq\n",
    "\n",
    "    in_val_tensor = torch.tensor(in_val, dtype=torch.float32, device=device)\n",
    "    in_cat_tensor = torch.tensor(in_cat, dtype=torch.float32, device=device)\n",
    "\n",
    "    in_val_tensor.requires_grad_()\n",
    "    in_cat_tensor.requires_grad_()\n",
    "\n",
    "    # Forward pass to get predictions\n",
    "    with torch.no_grad():\n",
    "        out_cat, out_val = model(in_cat_tensor, in_val_tensor)\n",
    "\n",
    "    # Backward pass to calculate Integrated Gradients\n",
    "    ig = IntegratedGradients(model)\n",
    "    attributions, approximation_error = ig.attribute((in_cat_tensor, in_val_tensor), target=target_class_index, return_convergence_delta=True)\n",
    "\n",
    "    out_cat = out_cat.cpu().numpy()\n",
    "    out_val = out_val.cpu().numpy()\n",
    "    attributions = attributions.cpu().numpy()\n",
    "\n",
    "    assert out_cat.shape[1] == out_val.shape[1] == 1\n",
    "\n",
    "    return out_cat, out_val, attributions, approximation_error.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_sequences_for_subject(dataset, subject_id):\n",
    "    # Assuming your dataset is a dictionary with keys 'cat', 'val', and 'time'\n",
    "    # Each key corresponds to the diagnosis, values, and time sequences for a subject\n",
    "    # Replace this with your actual data retrieval logic\n",
    "\n",
    "    icat = dataset['cat'][subject_id]\n",
    "    ival = dataset['val'][subject_id]\n",
    "    itime = dataset['time'][subject_id]\n",
    "\n",
    "    return icat, ival, itime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "rid = \"6\"  # Replace with an actual subject ID\n",
    "icat, ival, itime = get_input_sequences_for_subject(data, rid)  # Replace with your actual function to get input sequences\n",
    "\n",
    "out_cat, out_val, attributions, approximation_error = predict_subject_with_gradients(model, icat, ival, itime)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
