{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import cbig.osama2024.misc as misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', required=True)\n",
    "    parser.add_argument('--data', required=True)\n",
    "    parser.add_argument('--out', '-o', required=True)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def predict_subject(model, cat_seq, value_seq, time_seq):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression for a subject\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        cat_seq: sequence of diagnosis [nb_input_timpoints, nb_classes]\n",
    "        value_seq: sequence of other features [nb_input_timpoints, nb_features]\n",
    "        time_seq: months from baseline [nb_output_timpoints, nb_features]\n",
    "    nb_input_timpoints <= nb_output_timpoints\n",
    "    Returns:\n",
    "        out_cat: predicted diagnosis\n",
    "        out_val: predicted features\n",
    "    \"\"\"\n",
    "    in_val = np.full((len(time_seq), ) + value_seq.shape[1:], np.nan)\n",
    "    in_val[:len(value_seq)] = value_seq\n",
    "\n",
    "    in_cat = np.full((len(time_seq), ) + cat_seq.shape[1:], np.nan)\n",
    "    in_cat[:len(cat_seq)] = cat_seq\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_cat, out_val = model(in_cat, in_val)\n",
    "    out_cat = out_cat.cpu().numpy()\n",
    "    out_val = out_val.cpu().numpy()\n",
    "\n",
    "    assert out_cat.shape[1] == out_val.shape[1] == 1\n",
    "\n",
    "    return out_cat, out_val\n",
    "\n",
    "\n",
    "def predict(model, dataset, pred_start, duration, baseline):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression using a trained model\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        dataset: test data\n",
    "        pred_start (dictionary): the date at which prediction begins\n",
    "        duration (dictionary): how many months into the future to predict\n",
    "        baseline (dictionary): the baseline date\n",
    "    Returns:\n",
    "        dictionary which contains the following key/value pairs:\n",
    "            subjects: list of subject IDs\n",
    "            DX: list of diagnosis prediction for each subject\n",
    "            ADAS13: list of ADAS13 prediction for each subject\n",
    "            Ventricles: list of ventricular volume prediction for each subject\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ret = {'subjects': dataset.subjects}\n",
    "    ret['DX'] = []  # 1. likelihood of NL, MCI, and Dementia\n",
    "    ret['ADAS13'] = []  # 2. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['Ventricles'] = []  # 3. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['dates'] = misc.make_date_col(\n",
    "        [pred_start[s] for s in dataset.subjects], duration)\n",
    "\n",
    "    col = ['ADAS13', 'Ventricles', 'ICV']\n",
    "    indices = misc.get_index(list(dataset.value_fields()), col)\n",
    "    mean = model.mean[col].values.reshape(1, -1)\n",
    "    stds = model.stds[col].values.reshape(1, -1)\n",
    "\n",
    "    for i in range(len(dataset)):  # Iterate over subjects using indices\n",
    "        data = dataset[i]  # Access data using index\n",
    "        # print the columns\n",
    "        #print(data.keys())\n",
    "        rid = data['rid']\n",
    "        all_tp = data['tp'].squeeze(axis=1)\n",
    "        start = misc.month_between(pred_start[rid], baseline[rid])\n",
    "        assert np.all(all_tp == np.arange(len(all_tp)))\n",
    "        mask = all_tp < start\n",
    "        itime = np.arange(start + duration)\n",
    "        icat = np.asarray(\n",
    "            [misc.to_categorical(c, 3) for c in data['cat'][mask]])\n",
    "        ival = data['val'][:, None, :][mask]\n",
    "\n",
    "        ocat, oval = predict_subject(model, icat, ival, itime)\n",
    "        oval = oval[-duration:, 0, indices] * stds + mean\n",
    "\n",
    "        ret['DX'].append(ocat[-duration:, 0, :])\n",
    "        ret['ADAS13'].append(misc.add_ci_col(oval[:, 0], 1, 0, 85))\n",
    "        ret['Ventricles'].append(\n",
    "            misc.add_ci_col(oval[:, 1] / oval[:, 2], 5e-4, 0, 1))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'output/model.pt'\n",
    "data_path = 'output/val.pkl'\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torch.load(checkpoint_path)\n",
    "model.to(device)\n",
    "\n",
    "with open(data_path, 'rb') as fhandler:\n",
    "    data = pickle.load(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['baseline', 'pred_start', 'duration', 'mean', 'stds', 'VentICVstd', 'train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# print the keys of data\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data['test']\n",
    "pred_start = data['pred_start']\n",
    "duration = data['duration']\n",
    "baseline = data['baseline']\n",
    "\n",
    "model.eval()\n",
    "ret = {'subjects': test_data.subjects}\n",
    "ret['DX'] = []  # 1. likelihood of NL, MCI, and Dementia\n",
    "ret['ADAS13'] = []  # 2. (best guess, upper and lower bounds on 50% CI)\n",
    "ret['Ventricles'] = []  # 3. (best guess, upper and lower bounds on 50% CI)\n",
    "ret['dates'] = misc.make_date_col(\n",
    "    [pred_start[s] for s in test_data.subjects], duration)\n",
    "\n",
    "col = ['ADAS13', 'Ventricles', 'ICV']\n",
    "indices = misc.get_index(list(test_data.value_fields()), col)\n",
    "mean = model.mean[col].values.reshape(1, -1)\n",
    "stds = model.stds[col].values.reshape(1, -1)\n",
    "\n",
    "attributions = {}\n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    data_entry = test_data[i]\n",
    "    rid = data_entry['rid']\n",
    "    all_tp = data_entry['tp'].squeeze(axis=1)\n",
    "    start = misc.month_between(pred_start[rid], baseline[rid])\n",
    "    assert np.all(all_tp == np.arange(len(all_tp)))\n",
    "    mask = all_tp < start\n",
    "    itime = np.arange(start + duration)\n",
    "    icat = np.asarray(\n",
    "        [misc.to_categorical(c, 3) for c in data_entry['cat'][mask]])\n",
    "    ival = data_entry['val'][:, None, :][mask]\n",
    "    \n",
    "    in_val = np.full((len(itime), ) + ival.shape[1:], np.nan)\n",
    "    in_val[:len(ival)] = ival\n",
    "    \n",
    "    in_cat = np.full((len(itime), ) + icat.shape[1:], np.nan)\n",
    "    in_cat[:len(icat)] = icat\n",
    "    \n",
    "    input_val = torch.tensor(in_val, dtype=torch.float32).to(device)\n",
    "    input_cat = torch.tensor(in_cat, dtype=torch.float32).to(device)\n",
    "    # input_val = in_val\n",
    "    # input_cat = in_cat\n",
    "    \n",
    "    target = (0,0,0,0)\n",
    "    # convert to tensor\n",
    "    target_tensor = torch.tensor(target, dtype=torch.float32).to(device)\n",
    "    \n",
    "    attr_cat = integrated_gradients.attribute(\n",
    "        inputs=(input_cat, input_val), \n",
    "        baselines=None,  # You can provide baselines if needed\n",
    "        target=(0,1)  # You can specify the target output index if needed\n",
    "    )\n",
    "    \n",
    "    # Save attributions\n",
    "    attributions[rid] = {\n",
    "        'cat': attr_cat\n",
    "    }\n",
    "    \n",
    "    # ocat, oval = predict_subject(model, icat, ival, itime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(attributions[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "print(len(attributions.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(len(attributions[15]['cat'][0]))\n",
    "print(attributions[15]['cat'][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0437, 0.0000, 0.0000]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]],\n",
      "\n",
      "        [[   nan,    nan,    nan]]], dtype=torch.float64), tensor([[[-0.1916, -0.0954,  0.2437,  ..., -0.9247,  0.0076,  0.1262]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
      "       dtype=torch.float64))\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# print attribution for rid 7\n",
    "print(attributions[35]['cat'])\n",
    "\n",
    "#print dimension of the attribution\n",
    "print(len(attributions[7]['cat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (85,) and (85, 1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttributions for Subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_cat_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttribution\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Plot attributions over time steps\u001b[39;00m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime Step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribution\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\matplotlib\\pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3595\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:502\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    505\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2D, but have shapes (85,) and (85, 1, 3)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iterate over the attributions dictionary\n",
    "for rid, attr_dict in attributions.items():\n",
    "    # Extract the attributions for categorical input\n",
    "    attr_cat_tuple = attr_dict['cat']\n",
    "    \n",
    "    # Assuming the tuple contains (attributions_tensor, some_other_value)\n",
    "    attr_cat_tensor = attr_cat_tuple[0]  # Extract the tensor from the tuple\n",
    "    \n",
    "    # Plot the attributions for categorical input\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(f'Attributions for Subject {rid}')\n",
    "    plt.plot(attr_cat_tensor.cpu().numpy(), label='Attribution')  # Plot attributions over time steps\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Attribution')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
