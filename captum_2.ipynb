{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import cbig.osama2024.misc as misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', required=True)\n",
    "    parser.add_argument('--data', required=True)\n",
    "    parser.add_argument('--out', '-o', required=True)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def predict_subject(model, cat_seq, value_seq, time_seq):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression for a subject\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        cat_seq: sequence of diagnosis [nb_input_timpoints, nb_classes]\n",
    "        value_seq: sequence of other features [nb_input_timpoints, nb_features]\n",
    "        time_seq: months from baseline [nb_output_timpoints, nb_features]\n",
    "    nb_input_timpoints <= nb_output_timpoints\n",
    "    Returns:\n",
    "        out_cat: predicted diagnosis\n",
    "        out_val: predicted features\n",
    "    \"\"\"\n",
    "    in_val = np.full((len(time_seq), ) + value_seq.shape[1:], np.nan)\n",
    "    in_val[:len(value_seq)] = value_seq\n",
    "\n",
    "    in_cat = np.full((len(time_seq), ) + cat_seq.shape[1:], np.nan)\n",
    "    in_cat[:len(cat_seq)] = cat_seq\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_cat, out_val = model(in_cat, in_val)\n",
    "    out_cat = out_cat.cpu().numpy()\n",
    "    out_val = out_val.cpu().numpy()\n",
    "\n",
    "    assert out_cat.shape[1] == out_val.shape[1] == 1\n",
    "\n",
    "    return out_cat, out_val\n",
    "\n",
    "\n",
    "def predict(model, dataset, pred_start, duration, baseline):\n",
    "    \"\"\"\n",
    "    Predict Alzheimer’s disease progression using a trained model\n",
    "    Args:\n",
    "        model: trained pytorch model\n",
    "        dataset: test data\n",
    "        pred_start (dictionary): the date at which prediction begins\n",
    "        duration (dictionary): how many months into the future to predict\n",
    "        baseline (dictionary): the baseline date\n",
    "    Returns:\n",
    "        dictionary which contains the following key/value pairs:\n",
    "            subjects: list of subject IDs\n",
    "            DX: list of diagnosis prediction for each subject\n",
    "            ADAS13: list of ADAS13 prediction for each subject\n",
    "            Ventricles: list of ventricular volume prediction for each subject\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ret = {'subjects': dataset.subjects}\n",
    "    ret['DX'] = []  # 1. likelihood of NL, MCI, and Dementia\n",
    "    ret['ADAS13'] = []  # 2. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['Ventricles'] = []  # 3. (best guess, upper and lower bounds on 50% CI)\n",
    "    ret['dates'] = misc.make_date_col(\n",
    "        [pred_start[s] for s in dataset.subjects], duration)\n",
    "\n",
    "    col = ['ADAS13', 'Ventricles', 'ICV']\n",
    "    indices = misc.get_index(list(dataset.value_fields()), col)\n",
    "    mean = model.mean[col].values.reshape(1, -1)\n",
    "    stds = model.stds[col].values.reshape(1, -1)\n",
    "\n",
    "    for i in range(len(dataset)):  # Iterate over subjects using indices\n",
    "        data = dataset[i]  # Access data using index\n",
    "        # print the columns\n",
    "        #print(data.keys())\n",
    "        rid = data['rid']\n",
    "        all_tp = data['tp'].squeeze(axis=1)\n",
    "        start = misc.month_between(pred_start[rid], baseline[rid])\n",
    "        assert np.all(all_tp == np.arange(len(all_tp)))\n",
    "        mask = all_tp < start\n",
    "        itime = np.arange(start + duration)\n",
    "        icat = np.asarray(\n",
    "            [misc.to_categorical(c, 3) for c in data['cat'][mask]])\n",
    "        ival = data['val'][:, None, :][mask]\n",
    "\n",
    "        ocat, oval = predict_subject(model, icat, ival, itime)\n",
    "        oval = oval[-duration:, 0, indices] * stds + mean\n",
    "\n",
    "        ret['DX'].append(ocat[-duration:, 0, :])\n",
    "        ret['ADAS13'].append(misc.add_ci_col(oval[:, 0], 1, 0, 85))\n",
    "        ret['Ventricles'].append(\n",
    "            misc.add_ci_col(oval[:, 1] / oval[:, 2], 5e-4, 0, 1))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'output/model.pt'\n",
    "data_path = 'output/val.pkl'\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torch.load(checkpoint_path)\n",
    "model.to(device)\n",
    "\n",
    "with open(data_path, 'rb') as fhandler:\n",
    "    data = pickle.load(fhandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['baseline', 'pred_start', 'duration', 'mean', 'stds', 'VentICVstd', 'train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# print the keys of data\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a view of a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m input_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(in_cat, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# input_val = in_val\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# input_cat = in_cat\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m attr_cat \u001b[38;5;241m=\u001b[39m \u001b[43mintegrated_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can provide baselines if needed\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can specify the target output index if needed\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m attr_val \u001b[38;5;241m=\u001b[39m integrated_gradients\u001b[38;5;241m.\u001b[39mattribute(\n\u001b[0;32m     51\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m(input_cat, input_val),\n\u001b[0;32m     52\u001b[0m     baselines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# You can provide baselines if needed\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# You can specify the target output index if needed\u001b[39;00m\n\u001b[0;32m     54\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# cat_seq = data_entry['cat']\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# value_seq = data_entry['val']\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# pred_start = data['pred_start'][rid]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Save attributions\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[0;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m         num_examples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[0;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[0;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[0;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[0;32m    364\u001b[0m ]\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\captum\\_utils\\gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\captum\\_utils\\common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[0;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Professional\\Thesis\\RNN-AD\\RNN_py3\\cbig\\osama2024\\model.py:168\u001b[0m, in \u001b[0;36mRnnModelInterp.forward\u001b[1;34m(self, _cat_seq, _val_seq)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Fill in the missing features of the next timepoint\u001b[39;00m\n\u001b[0;32m    167\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(_val_seq[j])\n\u001b[1;32m--> 168\u001b[0m \u001b[43m_val_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m o_val[idx]  \u001b[38;5;66;03m# Directly modify the tensor without copy\u001b[39;00m\n\u001b[0;32m    170\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(_cat_seq[j])\n\u001b[0;32m    171\u001b[0m _cat_seq[j][idx] \u001b[38;5;241m=\u001b[39m o_cat[idx]  \u001b[38;5;66;03m# Directly modify the tensor without copy\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a view of a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "test_data = data['test']\n",
    "pred_start = data['pred_start']\n",
    "duration = data['duration']\n",
    "baseline = data['baseline']\n",
    "\n",
    "model.eval()\n",
    "ret = {'subjects': test_data.subjects}\n",
    "ret['DX'] = []  # 1. likelihood of NL, MCI, and Dementia\n",
    "ret['ADAS13'] = []  # 2. (best guess, upper and lower bounds on 50% CI)\n",
    "ret['Ventricles'] = []  # 3. (best guess, upper and lower bounds on 50% CI)\n",
    "ret['dates'] = misc.make_date_col(\n",
    "    [pred_start[s] for s in test_data.subjects], duration)\n",
    "\n",
    "col = ['ADAS13', 'Ventricles', 'ICV']\n",
    "indices = misc.get_index(list(test_data.value_fields()), col)\n",
    "mean = model.mean[col].values.reshape(1, -1)\n",
    "stds = model.stds[col].values.reshape(1, -1)\n",
    "\n",
    "attributions = {}\n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    data_entry = test_data[i]\n",
    "    rid = data_entry['rid']\n",
    "    all_tp = data_entry['tp'].squeeze(axis=1)\n",
    "    start = misc.month_between(pred_start[rid], baseline[rid])\n",
    "    assert np.all(all_tp == np.arange(len(all_tp)))\n",
    "    mask = all_tp < start\n",
    "    itime = np.arange(start + duration)\n",
    "    icat = np.asarray(\n",
    "        [misc.to_categorical(c, 3) for c in data_entry['cat'][mask]])\n",
    "    ival = data_entry['val'][:, None, :][mask]\n",
    "    \n",
    "    in_val = np.full((len(itime), ) + ival.shape[1:], np.nan)\n",
    "    in_val[:len(ival)] = ival\n",
    "    \n",
    "    in_cat = np.full((len(itime), ) + icat.shape[1:], np.nan)\n",
    "    in_cat[:len(icat)] = icat\n",
    "    \n",
    "    input_val = torch.tensor(in_val, dtype=torch.float32).to(device)\n",
    "    input_cat = torch.tensor(in_cat, dtype=torch.float32).to(device)\n",
    "    # input_val = in_val\n",
    "    # input_cat = in_cat\n",
    "    \n",
    "    attr_cat = integrated_gradients.attribute(\n",
    "        inputs=(input_cat, input_val), \n",
    "        baselines=None,  # You can provide baselines if needed\n",
    "        target=None  # You can specify the target output index if needed\n",
    "    )\n",
    "    \n",
    "    attr_val = integrated_gradients.attribute(\n",
    "        inputs=(input_cat, input_val),\n",
    "        baselines=None,  # You can provide baselines if needed\n",
    "        target=None  # You can specify the target output index if needed\n",
    "    )\n",
    "    \n",
    "    # cat_seq = data_entry['cat']\n",
    "    # value_seq = data_entry['val']\n",
    "    # pred_start = data['pred_start'][rid]\n",
    "    # duration = data['duration'][rid]\n",
    "    # baseline = data['baseline'][rid]\n",
    "    \n",
    "    # # Convert data to tensors\n",
    "    # cat_seq_tensor = torch.tensor(cat_seq, dtype=torch.float32).to(device)\n",
    "    # value_seq_tensor = torch.tensor(value_seq, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # # Compute integrated gradients\n",
    "    # attr_cat = integrated_gradients.attribute(\n",
    "    #     inputs=cat_seq_tensor,\n",
    "    #     baselines=None,  # You can provide baselines if needed\n",
    "    #     target=None  # You can specify the target output index if needed\n",
    "    # )\n",
    "    \n",
    "    # attr_value = integrated_gradients.attribute(\n",
    "    #     inputs=value_seq_tensor,\n",
    "    #     baselines=None,  # You can provide baselines if needed\n",
    "    #     target=None  # You can specify the target output index if needed\n",
    "    # )\n",
    "    \n",
    "    # Save attributions\n",
    "    attributions[rid] = {'cat_seq': attr_cat.cpu().numpy(), 'value_seq': attr_value.cpu().numpy()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
